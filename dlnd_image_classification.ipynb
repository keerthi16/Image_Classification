{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 2:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 984, 1: 1007, 2: 1010, 3: 995, 4: 1010, 5: 988, 6: 1008, 7: 1026, 8: 987, 9: 985}\n",
      "First 20 Labels: [1, 6, 6, 8, 8, 3, 4, 6, 0, 6, 0, 3, 6, 6, 5, 4, 8, 3, 2, 6]\n",
      "\n",
      "Example of Image 4:\n",
      "Image - Min Value: 0 Max Value: 255\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 8 Name: ship\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPQAUpugBoDBFDwCFKXoAKEzRA0Bh/xsLZO6u02DPIQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1158207f0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 2\n",
    "sample_id = 4\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    minimum = np.min(x)\n",
    "    maximum = np.max(x)\n",
    "    result = (x - minimum)/(maximum - minimum)\n",
    "    return result\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return np.eye(10)[x]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a bach of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, [None, *image_shape], name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, [None, n_classes], name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    i_d = int(x_tensor.shape[3])\n",
    "    o_d = conv_num_outputs\n",
    "    w_s = [*conv_ksize, i_d, o_d]\n",
    "    w = tf.Variable(tf.random_normal(w_s, stddev=0.1))\n",
    "    b = tf.Variable(tf.zeros(o_d))\n",
    "    conv_strides = [1, *conv_strides, 1]\n",
    "    x = tf.nn.conv2d(x_tensor, w, strides=conv_strides, padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    x = tf.nn.relu(x)\n",
    "    pool_ksize = [1, *pool_ksize, 1]\n",
    "    pool_strides = [1, *pool_strides, 1]\n",
    "    x = tf.nn.max_pool(x, pool_ksize, pool_strides, padding='SAME')\n",
    "    return x\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    batch_size, *img_size = x_tensor.get_shape().as_list()\n",
    "    img_size = img_size[0] * img_size[1] * img_size[2]\n",
    "    result = tf.reshape(x_tensor, [-1, img_size])\n",
    "    return result\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    w_shape = (int(x_tensor.get_shape().as_list()[1]), num_outputs)\n",
    "    w = tf.Variable(tf.random_normal(w_shape, stddev=0.1))\n",
    "    b = tf.Variable(tf.zeros(num_outputs))\n",
    "    x = tf.add(tf.matmul(x_tensor, w), b)\n",
    "    x = tf.nn.relu(x)\n",
    "    return x\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    w_shape = [int(x_tensor.get_shape().as_list()[1]), num_outputs]\n",
    "    w = tf.Variable(tf.random_normal(w_shape, stddev=0.1))\n",
    "    b = tf.Variable(tf.zeros(num_outputs))\n",
    "    x = tf.add(tf.matmul(x_tensor, w), b)\n",
    "    return x\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    x = conv2d_maxpool(x, 32, (3, 3), (1, 1), (2, 2), (2, 2))\n",
    "    x = conv2d_maxpool(x, 32, (3, 3), (2, 2), (2, 2), (2, 2))\n",
    "    x = conv2d_maxpool(x, 64, (3, 3), (1, 1), (2, 2), (2, 2))\n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    x = flatten(x)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    x = fully_conn(x, 512)\n",
    "    x = tf.nn.dropout(x, keep_prob)\n",
    "    x = fully_conn(x, 128)\n",
    "    x = tf.nn.dropout(x, keep_prob)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    o_p = output(x, 10)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return o_p\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={\n",
    "        x: feature_batch,\n",
    "        y: label_batch,\n",
    "        keep_prob: keep_probability\n",
    "    })\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost, feed_dict={\n",
    "        x: feature_batch,\n",
    "        y: label_batch,\n",
    "        keep_prob: 1.0\n",
    "    })\n",
    "    \n",
    "    valid_accuracy = session.run(accuracy, feed_dict={\n",
    "        x: valid_features,\n",
    "        y: valid_labels,\n",
    "        keep_prob: 1.0\n",
    "    })\n",
    "\n",
    "    print('The loss is: {:>10.5f} The validation accuracy is : {:0.6f}'.format(loss, valid_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 55\n",
    "batch_size = 256\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  The loss is:    2.18824 The validation accuracy is : 0.200200\n",
      "Epoch  2, CIFAR-10 Batch 1:  The loss is:    2.08014 The validation accuracy is : 0.285400\n",
      "Epoch  3, CIFAR-10 Batch 1:  The loss is:    1.86451 The validation accuracy is : 0.339400\n",
      "Epoch  4, CIFAR-10 Batch 1:  The loss is:    1.65891 The validation accuracy is : 0.386600\n",
      "Epoch  5, CIFAR-10 Batch 1:  The loss is:    1.53705 The validation accuracy is : 0.412400\n",
      "Epoch  6, CIFAR-10 Batch 1:  The loss is:    1.45449 The validation accuracy is : 0.431400\n",
      "Epoch  7, CIFAR-10 Batch 1:  The loss is:    1.38989 The validation accuracy is : 0.438400\n",
      "Epoch  8, CIFAR-10 Batch 1:  The loss is:    1.28314 The validation accuracy is : 0.451600\n",
      "Epoch  9, CIFAR-10 Batch 1:  The loss is:    1.20028 The validation accuracy is : 0.459200\n",
      "Epoch 10, CIFAR-10 Batch 1:  The loss is:    1.10944 The validation accuracy is : 0.477400\n",
      "Epoch 11, CIFAR-10 Batch 1:  The loss is:    1.00267 The validation accuracy is : 0.495000\n",
      "Epoch 12, CIFAR-10 Batch 1:  The loss is:    0.97553 The validation accuracy is : 0.485200\n",
      "Epoch 13, CIFAR-10 Batch 1:  The loss is:    0.94708 The validation accuracy is : 0.481600\n",
      "Epoch 14, CIFAR-10 Batch 1:  The loss is:    0.79851 The validation accuracy is : 0.501000\n",
      "Epoch 15, CIFAR-10 Batch 1:  The loss is:    0.75246 The validation accuracy is : 0.516200\n",
      "Epoch 16, CIFAR-10 Batch 1:  The loss is:    0.70484 The validation accuracy is : 0.525400\n",
      "Epoch 17, CIFAR-10 Batch 1:  The loss is:    0.66256 The validation accuracy is : 0.528000\n",
      "Epoch 18, CIFAR-10 Batch 1:  The loss is:    0.59507 The validation accuracy is : 0.531000\n",
      "Epoch 19, CIFAR-10 Batch 1:  The loss is:    0.56775 The validation accuracy is : 0.527800\n",
      "Epoch 20, CIFAR-10 Batch 1:  The loss is:    0.54631 The validation accuracy is : 0.543000\n",
      "Epoch 21, CIFAR-10 Batch 1:  The loss is:    0.52733 The validation accuracy is : 0.546000\n",
      "Epoch 22, CIFAR-10 Batch 1:  The loss is:    0.47327 The validation accuracy is : 0.537400\n",
      "Epoch 23, CIFAR-10 Batch 1:  The loss is:    0.45213 The validation accuracy is : 0.536200\n",
      "Epoch 24, CIFAR-10 Batch 1:  The loss is:    0.37056 The validation accuracy is : 0.551200\n",
      "Epoch 25, CIFAR-10 Batch 1:  The loss is:    0.38275 The validation accuracy is : 0.541200\n",
      "Epoch 26, CIFAR-10 Batch 1:  The loss is:    0.35213 The validation accuracy is : 0.554600\n",
      "Epoch 27, CIFAR-10 Batch 1:  The loss is:    0.36840 The validation accuracy is : 0.540600\n",
      "Epoch 28, CIFAR-10 Batch 1:  The loss is:    0.28733 The validation accuracy is : 0.558200\n",
      "Epoch 29, CIFAR-10 Batch 1:  The loss is:    0.28595 The validation accuracy is : 0.561800\n",
      "Epoch 30, CIFAR-10 Batch 1:  The loss is:    0.28683 The validation accuracy is : 0.553400\n",
      "Epoch 31, CIFAR-10 Batch 1:  The loss is:    0.24640 The validation accuracy is : 0.550000\n",
      "Epoch 32, CIFAR-10 Batch 1:  The loss is:    0.22294 The validation accuracy is : 0.542400\n",
      "Epoch 33, CIFAR-10 Batch 1:  The loss is:    0.19786 The validation accuracy is : 0.546400\n",
      "Epoch 34, CIFAR-10 Batch 1:  The loss is:    0.19696 The validation accuracy is : 0.559000\n",
      "Epoch 35, CIFAR-10 Batch 1:  The loss is:    0.18071 The validation accuracy is : 0.561800\n",
      "Epoch 36, CIFAR-10 Batch 1:  The loss is:    0.17977 The validation accuracy is : 0.556000\n",
      "Epoch 37, CIFAR-10 Batch 1:  The loss is:    0.14472 The validation accuracy is : 0.539600\n",
      "Epoch 38, CIFAR-10 Batch 1:  The loss is:    0.12333 The validation accuracy is : 0.544400\n",
      "Epoch 39, CIFAR-10 Batch 1:  The loss is:    0.13423 The validation accuracy is : 0.535400\n",
      "Epoch 40, CIFAR-10 Batch 1:  The loss is:    0.14761 The validation accuracy is : 0.545400\n",
      "Epoch 41, CIFAR-10 Batch 1:  The loss is:    0.12394 The validation accuracy is : 0.547600\n",
      "Epoch 42, CIFAR-10 Batch 1:  The loss is:    0.10514 The validation accuracy is : 0.554800\n",
      "Epoch 43, CIFAR-10 Batch 1:  The loss is:    0.08255 The validation accuracy is : 0.551200\n",
      "Epoch 44, CIFAR-10 Batch 1:  The loss is:    0.08836 The validation accuracy is : 0.537800\n",
      "Epoch 45, CIFAR-10 Batch 1:  The loss is:    0.09206 The validation accuracy is : 0.544400\n",
      "Epoch 46, CIFAR-10 Batch 1:  The loss is:    0.10348 The validation accuracy is : 0.528000\n",
      "Epoch 47, CIFAR-10 Batch 1:  The loss is:    0.09643 The validation accuracy is : 0.537800\n",
      "Epoch 48, CIFAR-10 Batch 1:  The loss is:    0.07921 The validation accuracy is : 0.533200\n",
      "Epoch 49, CIFAR-10 Batch 1:  The loss is:    0.05855 The validation accuracy is : 0.535600\n",
      "Epoch 50, CIFAR-10 Batch 1:  The loss is:    0.04953 The validation accuracy is : 0.547000\n",
      "Epoch 51, CIFAR-10 Batch 1:  The loss is:    0.05098 The validation accuracy is : 0.552000\n",
      "Epoch 52, CIFAR-10 Batch 1:  The loss is:    0.03982 The validation accuracy is : 0.549200\n",
      "Epoch 53, CIFAR-10 Batch 1:  The loss is:    0.03282 The validation accuracy is : 0.560400\n",
      "Epoch 54, CIFAR-10 Batch 1:  The loss is:    0.03624 The validation accuracy is : 0.549800\n",
      "Epoch 55, CIFAR-10 Batch 1:  The loss is:    0.03049 The validation accuracy is : 0.546800\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  The loss is:    2.19780 The validation accuracy is : 0.193800\n",
      "Epoch  1, CIFAR-10 Batch 2:  The loss is:    2.03655 The validation accuracy is : 0.307800\n",
      "Epoch  1, CIFAR-10 Batch 3:  The loss is:    1.62813 The validation accuracy is : 0.350200\n",
      "Epoch  1, CIFAR-10 Batch 4:  The loss is:    1.62410 The validation accuracy is : 0.386800\n",
      "Epoch  1, CIFAR-10 Batch 5:  The loss is:    1.51323 The validation accuracy is : 0.423200\n",
      "Epoch  2, CIFAR-10 Batch 1:  The loss is:    1.69287 The validation accuracy is : 0.429800\n",
      "Epoch  2, CIFAR-10 Batch 2:  The loss is:    1.55509 The validation accuracy is : 0.457800\n",
      "Epoch  2, CIFAR-10 Batch 3:  The loss is:    1.37985 The validation accuracy is : 0.449600\n",
      "Epoch  2, CIFAR-10 Batch 4:  The loss is:    1.36026 The validation accuracy is : 0.479600\n",
      "Epoch  2, CIFAR-10 Batch 5:  The loss is:    1.32164 The validation accuracy is : 0.488000\n",
      "Epoch  3, CIFAR-10 Batch 1:  The loss is:    1.37448 The validation accuracy is : 0.503400\n",
      "Epoch  3, CIFAR-10 Batch 2:  The loss is:    1.25539 The validation accuracy is : 0.495800\n",
      "Epoch  3, CIFAR-10 Batch 3:  The loss is:    1.17618 The validation accuracy is : 0.510400\n",
      "Epoch  3, CIFAR-10 Batch 4:  The loss is:    1.20926 The validation accuracy is : 0.521600\n",
      "Epoch  3, CIFAR-10 Batch 5:  The loss is:    1.21284 The validation accuracy is : 0.521800\n",
      "Epoch  4, CIFAR-10 Batch 1:  The loss is:    1.23364 The validation accuracy is : 0.536000\n",
      "Epoch  4, CIFAR-10 Batch 2:  The loss is:    1.10216 The validation accuracy is : 0.535200\n",
      "Epoch  4, CIFAR-10 Batch 3:  The loss is:    1.02002 The validation accuracy is : 0.538200\n",
      "Epoch  4, CIFAR-10 Batch 4:  The loss is:    1.07208 The validation accuracy is : 0.557400\n",
      "Epoch  4, CIFAR-10 Batch 5:  The loss is:    1.13615 The validation accuracy is : 0.550400\n",
      "Epoch  5, CIFAR-10 Batch 1:  The loss is:    1.07872 The validation accuracy is : 0.556400\n",
      "Epoch  5, CIFAR-10 Batch 2:  The loss is:    0.97879 The validation accuracy is : 0.560400\n",
      "Epoch  5, CIFAR-10 Batch 3:  The loss is:    0.91028 The validation accuracy is : 0.566200\n",
      "Epoch  5, CIFAR-10 Batch 4:  The loss is:    0.93911 The validation accuracy is : 0.582800\n",
      "Epoch  5, CIFAR-10 Batch 5:  The loss is:    1.01061 The validation accuracy is : 0.565200\n",
      "Epoch  6, CIFAR-10 Batch 1:  The loss is:    0.98820 The validation accuracy is : 0.571800\n",
      "Epoch  6, CIFAR-10 Batch 2:  The loss is:    0.81350 The validation accuracy is : 0.583600\n",
      "Epoch  6, CIFAR-10 Batch 3:  The loss is:    0.80877 The validation accuracy is : 0.576600\n",
      "Epoch  6, CIFAR-10 Batch 4:  The loss is:    0.88251 The validation accuracy is : 0.583800\n",
      "Epoch  6, CIFAR-10 Batch 5:  The loss is:    0.90452 The validation accuracy is : 0.597600\n",
      "Epoch  7, CIFAR-10 Batch 1:  The loss is:    0.88022 The validation accuracy is : 0.577200\n",
      "Epoch  7, CIFAR-10 Batch 2:  The loss is:    0.71896 The validation accuracy is : 0.597400\n",
      "Epoch  7, CIFAR-10 Batch 3:  The loss is:    0.72422 The validation accuracy is : 0.590600\n",
      "Epoch  7, CIFAR-10 Batch 4:  The loss is:    0.77180 The validation accuracy is : 0.611600\n",
      "Epoch  7, CIFAR-10 Batch 5:  The loss is:    0.80119 The validation accuracy is : 0.605000\n",
      "Epoch  8, CIFAR-10 Batch 1:  The loss is:    0.79916 The validation accuracy is : 0.596600\n",
      "Epoch  8, CIFAR-10 Batch 2:  The loss is:    0.68847 The validation accuracy is : 0.606200\n",
      "Epoch  8, CIFAR-10 Batch 3:  The loss is:    0.64903 The validation accuracy is : 0.613000\n",
      "Epoch  8, CIFAR-10 Batch 4:  The loss is:    0.72346 The validation accuracy is : 0.612800\n",
      "Epoch  8, CIFAR-10 Batch 5:  The loss is:    0.70262 The validation accuracy is : 0.623800\n",
      "Epoch  9, CIFAR-10 Batch 1:  The loss is:    0.74076 The validation accuracy is : 0.605200\n",
      "Epoch  9, CIFAR-10 Batch 2:  The loss is:    0.60331 The validation accuracy is : 0.614000\n",
      "Epoch  9, CIFAR-10 Batch 3:  The loss is:    0.56978 The validation accuracy is : 0.611800\n",
      "Epoch  9, CIFAR-10 Batch 4:  The loss is:    0.68652 The validation accuracy is : 0.620200\n",
      "Epoch  9, CIFAR-10 Batch 5:  The loss is:    0.61699 The validation accuracy is : 0.632400\n",
      "Epoch 10, CIFAR-10 Batch 1:  The loss is:    0.64968 The validation accuracy is : 0.618200\n",
      "Epoch 10, CIFAR-10 Batch 2:  The loss is:    0.53347 The validation accuracy is : 0.621800\n",
      "Epoch 10, CIFAR-10 Batch 3:  The loss is:    0.49493 The validation accuracy is : 0.622600\n",
      "Epoch 10, CIFAR-10 Batch 4:  The loss is:    0.62211 The validation accuracy is : 0.641600\n",
      "Epoch 10, CIFAR-10 Batch 5:  The loss is:    0.56827 The validation accuracy is : 0.638600\n",
      "Epoch 11, CIFAR-10 Batch 1:  The loss is:    0.67241 The validation accuracy is : 0.639400\n",
      "Epoch 11, CIFAR-10 Batch 2:  The loss is:    0.50112 The validation accuracy is : 0.637400\n",
      "Epoch 11, CIFAR-10 Batch 3:  The loss is:    0.52509 The validation accuracy is : 0.630800\n",
      "Epoch 11, CIFAR-10 Batch 4:  The loss is:    0.53702 The validation accuracy is : 0.647400\n",
      "Epoch 11, CIFAR-10 Batch 5:  The loss is:    0.54640 The validation accuracy is : 0.644800\n",
      "Epoch 12, CIFAR-10 Batch 1:  The loss is:    0.61404 The validation accuracy is : 0.606000\n",
      "Epoch 12, CIFAR-10 Batch 2:  The loss is:    0.45840 The validation accuracy is : 0.642400\n",
      "Epoch 12, CIFAR-10 Batch 3:  The loss is:    0.41920 The validation accuracy is : 0.648200\n",
      "Epoch 12, CIFAR-10 Batch 4:  The loss is:    0.48641 The validation accuracy is : 0.660800\n",
      "Epoch 12, CIFAR-10 Batch 5:  The loss is:    0.47226 The validation accuracy is : 0.658400\n",
      "Epoch 13, CIFAR-10 Batch 1:  The loss is:    0.49528 The validation accuracy is : 0.639400\n",
      "Epoch 13, CIFAR-10 Batch 2:  The loss is:    0.44449 The validation accuracy is : 0.639000\n",
      "Epoch 13, CIFAR-10 Batch 3:  The loss is:    0.39807 The validation accuracy is : 0.644400\n",
      "Epoch 13, CIFAR-10 Batch 4:  The loss is:    0.41245 The validation accuracy is : 0.659000\n",
      "Epoch 13, CIFAR-10 Batch 5:  The loss is:    0.43664 The validation accuracy is : 0.655200\n",
      "Epoch 14, CIFAR-10 Batch 1:  The loss is:    0.46436 The validation accuracy is : 0.640200\n",
      "Epoch 14, CIFAR-10 Batch 2:  The loss is:    0.35522 The validation accuracy is : 0.657200\n",
      "Epoch 14, CIFAR-10 Batch 3:  The loss is:    0.36270 The validation accuracy is : 0.644600\n",
      "Epoch 14, CIFAR-10 Batch 4:  The loss is:    0.40223 The validation accuracy is : 0.665600\n",
      "Epoch 14, CIFAR-10 Batch 5:  The loss is:    0.39737 The validation accuracy is : 0.667000\n",
      "Epoch 15, CIFAR-10 Batch 1:  The loss is:    0.39907 The validation accuracy is : 0.646600\n",
      "Epoch 15, CIFAR-10 Batch 2:  The loss is:    0.32208 The validation accuracy is : 0.664600\n",
      "Epoch 15, CIFAR-10 Batch 3:  The loss is:    0.30684 The validation accuracy is : 0.653400\n",
      "Epoch 15, CIFAR-10 Batch 4:  The loss is:    0.35462 The validation accuracy is : 0.659800\n",
      "Epoch 15, CIFAR-10 Batch 5:  The loss is:    0.36044 The validation accuracy is : 0.676000\n",
      "Epoch 16, CIFAR-10 Batch 1:  The loss is:    0.37526 The validation accuracy is : 0.655200\n",
      "Epoch 16, CIFAR-10 Batch 2:  The loss is:    0.30228 The validation accuracy is : 0.669200\n",
      "Epoch 16, CIFAR-10 Batch 3:  The loss is:    0.28114 The validation accuracy is : 0.657000\n",
      "Epoch 16, CIFAR-10 Batch 4:  The loss is:    0.33267 The validation accuracy is : 0.674000\n",
      "Epoch 16, CIFAR-10 Batch 5:  The loss is:    0.33034 The validation accuracy is : 0.673200\n",
      "Epoch 17, CIFAR-10 Batch 1:  The loss is:    0.31329 The validation accuracy is : 0.652800\n",
      "Epoch 17, CIFAR-10 Batch 2:  The loss is:    0.26951 The validation accuracy is : 0.665600\n",
      "Epoch 17, CIFAR-10 Batch 3:  The loss is:    0.27760 The validation accuracy is : 0.651000\n",
      "Epoch 17, CIFAR-10 Batch 4:  The loss is:    0.28833 The validation accuracy is : 0.669000\n",
      "Epoch 17, CIFAR-10 Batch 5:  The loss is:    0.31096 The validation accuracy is : 0.674000\n",
      "Epoch 18, CIFAR-10 Batch 1:  The loss is:    0.29502 The validation accuracy is : 0.649400\n",
      "Epoch 18, CIFAR-10 Batch 2:  The loss is:    0.24433 The validation accuracy is : 0.676400\n",
      "Epoch 18, CIFAR-10 Batch 3:  The loss is:    0.22374 The validation accuracy is : 0.655800\n",
      "Epoch 18, CIFAR-10 Batch 4:  The loss is:    0.29887 The validation accuracy is : 0.671800\n",
      "Epoch 18, CIFAR-10 Batch 5:  The loss is:    0.28546 The validation accuracy is : 0.677600\n",
      "Epoch 19, CIFAR-10 Batch 1:  The loss is:    0.28786 The validation accuracy is : 0.666800\n",
      "Epoch 19, CIFAR-10 Batch 2:  The loss is:    0.20003 The validation accuracy is : 0.661200\n",
      "Epoch 19, CIFAR-10 Batch 3:  The loss is:    0.22587 The validation accuracy is : 0.660000\n",
      "Epoch 19, CIFAR-10 Batch 4:  The loss is:    0.26276 The validation accuracy is : 0.682800\n",
      "Epoch 19, CIFAR-10 Batch 5:  The loss is:    0.25264 The validation accuracy is : 0.677200\n",
      "Epoch 20, CIFAR-10 Batch 1:  The loss is:    0.26735 The validation accuracy is : 0.652800\n",
      "Epoch 20, CIFAR-10 Batch 2:  The loss is:    0.20010 The validation accuracy is : 0.663800\n",
      "Epoch 20, CIFAR-10 Batch 3:  The loss is:    0.21854 The validation accuracy is : 0.671000\n",
      "Epoch 20, CIFAR-10 Batch 4:  The loss is:    0.26016 The validation accuracy is : 0.678800\n",
      "Epoch 20, CIFAR-10 Batch 5:  The loss is:    0.22751 The validation accuracy is : 0.689600\n",
      "Epoch 21, CIFAR-10 Batch 1:  The loss is:    0.26287 The validation accuracy is : 0.676600\n",
      "Epoch 21, CIFAR-10 Batch 2:  The loss is:    0.18388 The validation accuracy is : 0.674000\n",
      "Epoch 21, CIFAR-10 Batch 3:  The loss is:    0.20736 The validation accuracy is : 0.652800\n",
      "Epoch 21, CIFAR-10 Batch 4:  The loss is:    0.26900 The validation accuracy is : 0.679600\n",
      "Epoch 21, CIFAR-10 Batch 5:  The loss is:    0.20391 The validation accuracy is : 0.687000\n",
      "Epoch 22, CIFAR-10 Batch 1:  The loss is:    0.22673 The validation accuracy is : 0.679400\n",
      "Epoch 22, CIFAR-10 Batch 2:  The loss is:    0.15882 The validation accuracy is : 0.666400\n",
      "Epoch 22, CIFAR-10 Batch 3:  The loss is:    0.21905 The validation accuracy is : 0.649600\n",
      "Epoch 22, CIFAR-10 Batch 4:  The loss is:    0.25317 The validation accuracy is : 0.681400\n",
      "Epoch 22, CIFAR-10 Batch 5:  The loss is:    0.22206 The validation accuracy is : 0.672000\n",
      "Epoch 23, CIFAR-10 Batch 1:  The loss is:    0.22382 The validation accuracy is : 0.678400\n",
      "Epoch 23, CIFAR-10 Batch 2:  The loss is:    0.15862 The validation accuracy is : 0.671800\n",
      "Epoch 23, CIFAR-10 Batch 3:  The loss is:    0.21751 The validation accuracy is : 0.652600\n",
      "Epoch 23, CIFAR-10 Batch 4:  The loss is:    0.20196 The validation accuracy is : 0.677800\n",
      "Epoch 23, CIFAR-10 Batch 5:  The loss is:    0.18712 The validation accuracy is : 0.681400\n",
      "Epoch 24, CIFAR-10 Batch 1:  The loss is:    0.19384 The validation accuracy is : 0.688600\n",
      "Epoch 24, CIFAR-10 Batch 2:  The loss is:    0.14223 The validation accuracy is : 0.669000\n",
      "Epoch 24, CIFAR-10 Batch 3:  The loss is:    0.17610 The validation accuracy is : 0.647800\n",
      "Epoch 24, CIFAR-10 Batch 4:  The loss is:    0.17562 The validation accuracy is : 0.693200\n",
      "Epoch 24, CIFAR-10 Batch 5:  The loss is:    0.15886 The validation accuracy is : 0.695600\n",
      "Epoch 25, CIFAR-10 Batch 1:  The loss is:    0.19614 The validation accuracy is : 0.682600\n",
      "Epoch 25, CIFAR-10 Batch 2:  The loss is:    0.12780 The validation accuracy is : 0.679800\n",
      "Epoch 25, CIFAR-10 Batch 3:  The loss is:    0.14912 The validation accuracy is : 0.654400\n",
      "Epoch 25, CIFAR-10 Batch 4:  The loss is:    0.15072 The validation accuracy is : 0.691400\n",
      "Epoch 25, CIFAR-10 Batch 5:  The loss is:    0.14091 The validation accuracy is : 0.693400\n",
      "Epoch 26, CIFAR-10 Batch 1:  The loss is:    0.17760 The validation accuracy is : 0.685600\n",
      "Epoch 26, CIFAR-10 Batch 2:  The loss is:    0.13063 The validation accuracy is : 0.683600\n",
      "Epoch 26, CIFAR-10 Batch 3:  The loss is:    0.13067 The validation accuracy is : 0.667400\n",
      "Epoch 26, CIFAR-10 Batch 4:  The loss is:    0.15561 The validation accuracy is : 0.682000\n",
      "Epoch 26, CIFAR-10 Batch 5:  The loss is:    0.15860 The validation accuracy is : 0.679200\n",
      "Epoch 27, CIFAR-10 Batch 1:  The loss is:    0.17738 The validation accuracy is : 0.684600\n",
      "Epoch 27, CIFAR-10 Batch 2:  The loss is:    0.12212 The validation accuracy is : 0.667000\n",
      "Epoch 27, CIFAR-10 Batch 3:  The loss is:    0.15797 The validation accuracy is : 0.678600\n",
      "Epoch 27, CIFAR-10 Batch 4:  The loss is:    0.16200 The validation accuracy is : 0.686600\n",
      "Epoch 27, CIFAR-10 Batch 5:  The loss is:    0.12842 The validation accuracy is : 0.680600\n",
      "Epoch 28, CIFAR-10 Batch 1:  The loss is:    0.16855 The validation accuracy is : 0.691000\n",
      "Epoch 28, CIFAR-10 Batch 2:  The loss is:    0.15078 The validation accuracy is : 0.666800\n",
      "Epoch 28, CIFAR-10 Batch 3:  The loss is:    0.12901 The validation accuracy is : 0.682000\n",
      "Epoch 28, CIFAR-10 Batch 4:  The loss is:    0.13619 The validation accuracy is : 0.689600\n",
      "Epoch 28, CIFAR-10 Batch 5:  The loss is:    0.12408 The validation accuracy is : 0.666600\n",
      "Epoch 29, CIFAR-10 Batch 1:  The loss is:    0.17602 The validation accuracy is : 0.680000\n",
      "Epoch 29, CIFAR-10 Batch 2:  The loss is:    0.12600 The validation accuracy is : 0.661200\n",
      "Epoch 29, CIFAR-10 Batch 3:  The loss is:    0.12176 The validation accuracy is : 0.673600\n",
      "Epoch 29, CIFAR-10 Batch 4:  The loss is:    0.14210 The validation accuracy is : 0.689800\n",
      "Epoch 29, CIFAR-10 Batch 5:  The loss is:    0.12395 The validation accuracy is : 0.680000\n",
      "Epoch 30, CIFAR-10 Batch 1:  The loss is:    0.15365 The validation accuracy is : 0.681200\n",
      "Epoch 30, CIFAR-10 Batch 2:  The loss is:    0.12435 The validation accuracy is : 0.667800\n",
      "Epoch 30, CIFAR-10 Batch 3:  The loss is:    0.11471 The validation accuracy is : 0.685800\n",
      "Epoch 30, CIFAR-10 Batch 4:  The loss is:    0.12156 The validation accuracy is : 0.691600\n",
      "Epoch 30, CIFAR-10 Batch 5:  The loss is:    0.13790 The validation accuracy is : 0.693800\n",
      "Epoch 31, CIFAR-10 Batch 1:  The loss is:    0.15337 The validation accuracy is : 0.688800\n",
      "Epoch 31, CIFAR-10 Batch 2:  The loss is:    0.11730 The validation accuracy is : 0.677000\n",
      "Epoch 31, CIFAR-10 Batch 3:  The loss is:    0.09233 The validation accuracy is : 0.684400\n",
      "Epoch 31, CIFAR-10 Batch 4:  The loss is:    0.10490 The validation accuracy is : 0.697600\n",
      "Epoch 31, CIFAR-10 Batch 5:  The loss is:    0.11992 The validation accuracy is : 0.690000\n",
      "Epoch 32, CIFAR-10 Batch 1:  The loss is:    0.13826 The validation accuracy is : 0.680200\n",
      "Epoch 32, CIFAR-10 Batch 2:  The loss is:    0.10437 The validation accuracy is : 0.668000\n",
      "Epoch 32, CIFAR-10 Batch 3:  The loss is:    0.10153 The validation accuracy is : 0.685600\n",
      "Epoch 32, CIFAR-10 Batch 4:  The loss is:    0.09528 The validation accuracy is : 0.690800\n",
      "Epoch 32, CIFAR-10 Batch 5:  The loss is:    0.09918 The validation accuracy is : 0.685800\n",
      "Epoch 33, CIFAR-10 Batch 1:  The loss is:    0.11491 The validation accuracy is : 0.679800\n",
      "Epoch 33, CIFAR-10 Batch 2:  The loss is:    0.12071 The validation accuracy is : 0.665000\n",
      "Epoch 33, CIFAR-10 Batch 3:  The loss is:    0.11241 The validation accuracy is : 0.691600\n",
      "Epoch 33, CIFAR-10 Batch 4:  The loss is:    0.09405 The validation accuracy is : 0.687600\n",
      "Epoch 33, CIFAR-10 Batch 5:  The loss is:    0.09478 The validation accuracy is : 0.694000\n",
      "Epoch 34, CIFAR-10 Batch 1:  The loss is:    0.13598 The validation accuracy is : 0.667400\n",
      "Epoch 34, CIFAR-10 Batch 2:  The loss is:    0.11311 The validation accuracy is : 0.659000\n",
      "Epoch 34, CIFAR-10 Batch 3:  The loss is:    0.08617 The validation accuracy is : 0.684400\n",
      "Epoch 34, CIFAR-10 Batch 4:  The loss is:    0.07567 The validation accuracy is : 0.693600\n",
      "Epoch 34, CIFAR-10 Batch 5:  The loss is:    0.08544 The validation accuracy is : 0.696800\n",
      "Epoch 35, CIFAR-10 Batch 1:  The loss is:    0.11529 The validation accuracy is : 0.678200\n",
      "Epoch 35, CIFAR-10 Batch 2:  The loss is:    0.09825 The validation accuracy is : 0.656400\n",
      "Epoch 35, CIFAR-10 Batch 3:  The loss is:    0.08900 The validation accuracy is : 0.689600\n",
      "Epoch 35, CIFAR-10 Batch 4:  The loss is:    0.08174 The validation accuracy is : 0.695000\n",
      "Epoch 35, CIFAR-10 Batch 5:  The loss is:    0.08813 The validation accuracy is : 0.693800\n",
      "Epoch 36, CIFAR-10 Batch 1:  The loss is:    0.09621 The validation accuracy is : 0.675800\n",
      "Epoch 36, CIFAR-10 Batch 2:  The loss is:    0.07573 The validation accuracy is : 0.678000\n",
      "Epoch 36, CIFAR-10 Batch 3:  The loss is:    0.06218 The validation accuracy is : 0.690400\n",
      "Epoch 36, CIFAR-10 Batch 4:  The loss is:    0.08862 The validation accuracy is : 0.683200\n",
      "Epoch 36, CIFAR-10 Batch 5:  The loss is:    0.09714 The validation accuracy is : 0.695600\n",
      "Epoch 37, CIFAR-10 Batch 1:  The loss is:    0.13333 The validation accuracy is : 0.679800\n",
      "Epoch 37, CIFAR-10 Batch 2:  The loss is:    0.06668 The validation accuracy is : 0.681600\n",
      "Epoch 37, CIFAR-10 Batch 3:  The loss is:    0.07563 The validation accuracy is : 0.690400\n",
      "Epoch 37, CIFAR-10 Batch 4:  The loss is:    0.07646 The validation accuracy is : 0.689000\n",
      "Epoch 37, CIFAR-10 Batch 5:  The loss is:    0.09038 The validation accuracy is : 0.686800\n",
      "Epoch 38, CIFAR-10 Batch 1:  The loss is:    0.09989 The validation accuracy is : 0.669000\n",
      "Epoch 38, CIFAR-10 Batch 2:  The loss is:    0.08345 The validation accuracy is : 0.690800\n",
      "Epoch 38, CIFAR-10 Batch 3:  The loss is:    0.07051 The validation accuracy is : 0.685200\n",
      "Epoch 38, CIFAR-10 Batch 4:  The loss is:    0.08422 The validation accuracy is : 0.685800\n",
      "Epoch 38, CIFAR-10 Batch 5:  The loss is:    0.08911 The validation accuracy is : 0.678000\n",
      "Epoch 39, CIFAR-10 Batch 1:  The loss is:    0.11078 The validation accuracy is : 0.676800\n",
      "Epoch 39, CIFAR-10 Batch 2:  The loss is:    0.06565 The validation accuracy is : 0.691600\n",
      "Epoch 39, CIFAR-10 Batch 3:  The loss is:    0.06789 The validation accuracy is : 0.689600\n",
      "Epoch 39, CIFAR-10 Batch 4:  The loss is:    0.05850 The validation accuracy is : 0.685200\n",
      "Epoch 39, CIFAR-10 Batch 5:  The loss is:    0.05766 The validation accuracy is : 0.687200\n",
      "Epoch 40, CIFAR-10 Batch 1:  The loss is:    0.11149 The validation accuracy is : 0.675400\n",
      "Epoch 40, CIFAR-10 Batch 2:  The loss is:    0.07063 The validation accuracy is : 0.682400\n",
      "Epoch 40, CIFAR-10 Batch 3:  The loss is:    0.07205 The validation accuracy is : 0.693400\n",
      "Epoch 40, CIFAR-10 Batch 4:  The loss is:    0.05862 The validation accuracy is : 0.682200\n",
      "Epoch 40, CIFAR-10 Batch 5:  The loss is:    0.07550 The validation accuracy is : 0.665000\n",
      "Epoch 41, CIFAR-10 Batch 1:  The loss is:    0.09216 The validation accuracy is : 0.676000\n",
      "Epoch 41, CIFAR-10 Batch 2:  The loss is:    0.07431 The validation accuracy is : 0.680800\n",
      "Epoch 41, CIFAR-10 Batch 3:  The loss is:    0.06436 The validation accuracy is : 0.693200\n",
      "Epoch 41, CIFAR-10 Batch 4:  The loss is:    0.05740 The validation accuracy is : 0.684200\n",
      "Epoch 41, CIFAR-10 Batch 5:  The loss is:    0.06339 The validation accuracy is : 0.671000\n",
      "Epoch 42, CIFAR-10 Batch 1:  The loss is:    0.10297 The validation accuracy is : 0.672800\n",
      "Epoch 42, CIFAR-10 Batch 2:  The loss is:    0.05759 The validation accuracy is : 0.688600\n",
      "Epoch 42, CIFAR-10 Batch 3:  The loss is:    0.05767 The validation accuracy is : 0.695600\n",
      "Epoch 42, CIFAR-10 Batch 4:  The loss is:    0.07771 The validation accuracy is : 0.691000\n",
      "Epoch 42, CIFAR-10 Batch 5:  The loss is:    0.05112 The validation accuracy is : 0.689600\n",
      "Epoch 43, CIFAR-10 Batch 1:  The loss is:    0.07531 The validation accuracy is : 0.678400\n",
      "Epoch 43, CIFAR-10 Batch 2:  The loss is:    0.05223 The validation accuracy is : 0.685600\n",
      "Epoch 43, CIFAR-10 Batch 3:  The loss is:    0.04292 The validation accuracy is : 0.692200\n",
      "Epoch 43, CIFAR-10 Batch 4:  The loss is:    0.05284 The validation accuracy is : 0.696200\n",
      "Epoch 43, CIFAR-10 Batch 5:  The loss is:    0.04398 The validation accuracy is : 0.680200\n",
      "Epoch 44, CIFAR-10 Batch 1:  The loss is:    0.06813 The validation accuracy is : 0.689800\n",
      "Epoch 44, CIFAR-10 Batch 2:  The loss is:    0.05044 The validation accuracy is : 0.686600\n",
      "Epoch 44, CIFAR-10 Batch 3:  The loss is:    0.04733 The validation accuracy is : 0.693400\n",
      "Epoch 44, CIFAR-10 Batch 4:  The loss is:    0.06319 The validation accuracy is : 0.675400\n",
      "Epoch 44, CIFAR-10 Batch 5:  The loss is:    0.08395 The validation accuracy is : 0.671200\n",
      "Epoch 45, CIFAR-10 Batch 1:  The loss is:    0.07056 The validation accuracy is : 0.683400\n",
      "Epoch 45, CIFAR-10 Batch 2:  The loss is:    0.06873 The validation accuracy is : 0.682800\n",
      "Epoch 45, CIFAR-10 Batch 3:  The loss is:    0.05522 The validation accuracy is : 0.691800\n",
      "Epoch 45, CIFAR-10 Batch 4:  The loss is:    0.05154 The validation accuracy is : 0.689600\n",
      "Epoch 45, CIFAR-10 Batch 5:  The loss is:    0.06437 The validation accuracy is : 0.680600\n",
      "Epoch 46, CIFAR-10 Batch 1:  The loss is:    0.06905 The validation accuracy is : 0.677400\n",
      "Epoch 46, CIFAR-10 Batch 2:  The loss is:    0.05392 The validation accuracy is : 0.682400\n",
      "Epoch 46, CIFAR-10 Batch 3:  The loss is:    0.04620 The validation accuracy is : 0.688800\n",
      "Epoch 46, CIFAR-10 Batch 4:  The loss is:    0.05427 The validation accuracy is : 0.685000\n",
      "Epoch 46, CIFAR-10 Batch 5:  The loss is:    0.06564 The validation accuracy is : 0.683600\n",
      "Epoch 47, CIFAR-10 Batch 1:  The loss is:    0.05327 The validation accuracy is : 0.678600\n",
      "Epoch 47, CIFAR-10 Batch 2:  The loss is:    0.05035 The validation accuracy is : 0.699800\n",
      "Epoch 47, CIFAR-10 Batch 3:  The loss is:    0.04401 The validation accuracy is : 0.686800\n",
      "Epoch 47, CIFAR-10 Batch 4:  The loss is:    0.04782 The validation accuracy is : 0.681600\n",
      "Epoch 47, CIFAR-10 Batch 5:  The loss is:    0.08023 The validation accuracy is : 0.688800\n",
      "Epoch 48, CIFAR-10 Batch 1:  The loss is:    0.05060 The validation accuracy is : 0.679400\n",
      "Epoch 48, CIFAR-10 Batch 2:  The loss is:    0.05476 The validation accuracy is : 0.696600\n",
      "Epoch 48, CIFAR-10 Batch 3:  The loss is:    0.03209 The validation accuracy is : 0.688400\n",
      "Epoch 48, CIFAR-10 Batch 4:  The loss is:    0.03501 The validation accuracy is : 0.691000\n",
      "Epoch 48, CIFAR-10 Batch 5:  The loss is:    0.05549 The validation accuracy is : 0.688400\n",
      "Epoch 49, CIFAR-10 Batch 1:  The loss is:    0.05020 The validation accuracy is : 0.685800\n",
      "Epoch 49, CIFAR-10 Batch 2:  The loss is:    0.04192 The validation accuracy is : 0.691000\n",
      "Epoch 49, CIFAR-10 Batch 3:  The loss is:    0.03722 The validation accuracy is : 0.686800\n",
      "Epoch 49, CIFAR-10 Batch 4:  The loss is:    0.04852 The validation accuracy is : 0.680400\n",
      "Epoch 49, CIFAR-10 Batch 5:  The loss is:    0.04472 The validation accuracy is : 0.691200\n",
      "Epoch 50, CIFAR-10 Batch 1:  The loss is:    0.05505 The validation accuracy is : 0.672200\n",
      "Epoch 50, CIFAR-10 Batch 2:  The loss is:    0.03870 The validation accuracy is : 0.686200\n",
      "Epoch 50, CIFAR-10 Batch 3:  The loss is:    0.06750 The validation accuracy is : 0.678000\n",
      "Epoch 50, CIFAR-10 Batch 4:  The loss is:    0.06374 The validation accuracy is : 0.666600\n",
      "Epoch 50, CIFAR-10 Batch 5:  The loss is:    0.05140 The validation accuracy is : 0.684600\n",
      "Epoch 51, CIFAR-10 Batch 1:  The loss is:    0.05369 The validation accuracy is : 0.664400\n",
      "Epoch 51, CIFAR-10 Batch 2:  The loss is:    0.05352 The validation accuracy is : 0.688800\n",
      "Epoch 51, CIFAR-10 Batch 3:  The loss is:    0.03362 The validation accuracy is : 0.689400\n",
      "Epoch 51, CIFAR-10 Batch 4:  The loss is:    0.04861 The validation accuracy is : 0.684000\n",
      "Epoch 51, CIFAR-10 Batch 5:  The loss is:    0.05438 The validation accuracy is : 0.684400\n",
      "Epoch 52, CIFAR-10 Batch 1:  The loss is:    0.05367 The validation accuracy is : 0.659000\n",
      "Epoch 52, CIFAR-10 Batch 2:  The loss is:    0.04652 The validation accuracy is : 0.690000\n",
      "Epoch 52, CIFAR-10 Batch 3:  The loss is:    0.04158 The validation accuracy is : 0.685000\n",
      "Epoch 52, CIFAR-10 Batch 4:  The loss is:    0.05710 The validation accuracy is : 0.673800\n",
      "Epoch 52, CIFAR-10 Batch 5:  The loss is:    0.05682 The validation accuracy is : 0.688800\n",
      "Epoch 53, CIFAR-10 Batch 1:  The loss is:    0.03867 The validation accuracy is : 0.671600\n",
      "Epoch 53, CIFAR-10 Batch 2:  The loss is:    0.05015 The validation accuracy is : 0.687000\n",
      "Epoch 53, CIFAR-10 Batch 3:  The loss is:    0.04209 The validation accuracy is : 0.674200\n",
      "Epoch 53, CIFAR-10 Batch 4:  The loss is:    0.04512 The validation accuracy is : 0.681400\n",
      "Epoch 53, CIFAR-10 Batch 5:  The loss is:    0.05464 The validation accuracy is : 0.691800\n",
      "Epoch 54, CIFAR-10 Batch 1:  The loss is:    0.04228 The validation accuracy is : 0.674800\n",
      "Epoch 54, CIFAR-10 Batch 2:  The loss is:    0.04889 The validation accuracy is : 0.690200\n",
      "Epoch 54, CIFAR-10 Batch 3:  The loss is:    0.03284 The validation accuracy is : 0.687600\n",
      "Epoch 54, CIFAR-10 Batch 4:  The loss is:    0.05975 The validation accuracy is : 0.681400\n",
      "Epoch 54, CIFAR-10 Batch 5:  The loss is:    0.06151 The validation accuracy is : 0.684000\n",
      "Epoch 55, CIFAR-10 Batch 1:  The loss is:    0.03484 The validation accuracy is : 0.682600\n",
      "Epoch 55, CIFAR-10 Batch 2:  The loss is:    0.03561 The validation accuracy is : 0.690000\n",
      "Epoch 55, CIFAR-10 Batch 3:  The loss is:    0.02936 The validation accuracy is : 0.689400\n",
      "Epoch 55, CIFAR-10 Batch 4:  The loss is:    0.04421 The validation accuracy is : 0.677600\n",
      "Epoch 55, CIFAR-10 Batch 5:  The loss is:    0.04223 The validation accuracy is : 0.682000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.67236328125\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niEj0/wFOTSaGMF+s4wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107f88f60>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 50-70% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 70%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
